# VisionGuide

**VisionGuide** is a mobile application developed using React Native and Firebase Cloud Vision, aimed at assisting visually impaired individuals in navigating their surroundings. This project serves as my final year project for the BTech program in Computer Science.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgements](#acknowledgements)

## Features

- **Image Recognition:** Utilizes Firebase Cloud Vision to identify objects, texts, and environments in real-time.
- **Voice Feedback:** Provides auditory descriptions of identified objects to assist users in understanding their surroundings.
- **User-Friendly Interface:** Designed with accessibility in mind, ensuring easy navigation for visually impaired users.
- **Offline Mode:** Allows basic functionality without an internet connection, using pre-trained models.

## Technologies Used

- **React Native**: Framework for building the mobile application.
- **Firebase**: Backend service providing authentication and Cloud Vision functionalities.
- **JavaScript**: Programming language used for application logic.
- **Expo**: Toolchain for developing React Native apps.

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/visionguide.git



<img width="427" alt="Screenshot 2024-09-29 at 3 26 48 PM" src="https://github.com/user-attachments/assets/8876fcf5-2400-46dd-a3c2-00c54a98beb8">

